{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transform Class.\n",
    "DictT.dot is a method corresponding to the DWT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictT(object):\n",
    "\n",
    "    def __init__(self, name, level):\n",
    "            self.name = name\n",
    "            self.level = level\n",
    "            self.sizes = []\n",
    "\n",
    "    def dot(self, mat):\n",
    "\n",
    "        m = []\n",
    "\n",
    "        if mat.shape[0] != mat.size:\n",
    "            for i in xrange(mat.shape[1]):\n",
    "                c = pywt.wavedec(mat[:, i], self.name, level=self.level)\n",
    "                self.sizes.append(map(len, c))\n",
    "                c = np.concatenate(c)\n",
    "                m.append(c)\n",
    "            return np.asarray(m).T\n",
    "        else:\n",
    "            c = pywt.wavedec(mat, self.name, level=self.level)\n",
    "            self.sizes.append(map(len, c))\n",
    "            return np.concatenate(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/training_input.csv', delimiter=',')\n",
    "output = pd.read_csv('Data/training_output.csv', delimiter=';')\n",
    "test = pd.read_csv('Data/testing_input.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows with no or several missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, output, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_filled = train.drop(pd.isnull(train).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "train_missing = train[~train[\"ID\"].isin(train_filled[\"ID\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>09:30:00</th>\n",
       "      <th>09:35:00</th>\n",
       "      <th>09:40:00</th>\n",
       "      <th>09:45:00</th>\n",
       "      <th>09:50:00</th>\n",
       "      <th>09:55:00</th>\n",
       "      <th>10:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>13:15:00</th>\n",
       "      <th>13:20:00</th>\n",
       "      <th>13:25:00</th>\n",
       "      <th>13:30:00</th>\n",
       "      <th>13:35:00</th>\n",
       "      <th>13:40:00</th>\n",
       "      <th>13:45:00</th>\n",
       "      <th>13:50:00</th>\n",
       "      <th>13:55:00</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>8091607.23</td>\n",
       "      <td>200855.00</td>\n",
       "      <td>254585.18</td>\n",
       "      <td>182094.78</td>\n",
       "      <td>239248.65</td>\n",
       "      <td>295739.52</td>\n",
       "      <td>224983.14</td>\n",
       "      <td>...</td>\n",
       "      <td>134951.50</td>\n",
       "      <td>172651.50</td>\n",
       "      <td>231768.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10164.00</td>\n",
       "      <td>161273.64</td>\n",
       "      <td>245219.00</td>\n",
       "      <td>118459.64</td>\n",
       "      <td>70953.90</td>\n",
       "      <td>7669334.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>3967038.72</td>\n",
       "      <td>49270.40</td>\n",
       "      <td>72597.00</td>\n",
       "      <td>49056.54</td>\n",
       "      <td>105244.80</td>\n",
       "      <td>109664.24</td>\n",
       "      <td>72702.00</td>\n",
       "      <td>...</td>\n",
       "      <td>94930.00</td>\n",
       "      <td>109808.12</td>\n",
       "      <td>53813.32</td>\n",
       "      <td>32897.56</td>\n",
       "      <td>142312.95</td>\n",
       "      <td>20532.20</td>\n",
       "      <td>20807.80</td>\n",
       "      <td>38365.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3591258.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4902746.25</td>\n",
       "      <td>123692.64</td>\n",
       "      <td>126432.00</td>\n",
       "      <td>90729.22</td>\n",
       "      <td>225985.34</td>\n",
       "      <td>127063.09</td>\n",
       "      <td>...</td>\n",
       "      <td>45155.70</td>\n",
       "      <td>116440.34</td>\n",
       "      <td>106385.16</td>\n",
       "      <td>89622.00</td>\n",
       "      <td>124051.29</td>\n",
       "      <td>68860.00</td>\n",
       "      <td>79177.41</td>\n",
       "      <td>299000.72</td>\n",
       "      <td>185450.66</td>\n",
       "      <td>9088162.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>5642713.00</td>\n",
       "      <td>168978.59</td>\n",
       "      <td>252366.66</td>\n",
       "      <td>212968.04</td>\n",
       "      <td>92013.80</td>\n",
       "      <td>102185.00</td>\n",
       "      <td>186739.00</td>\n",
       "      <td>...</td>\n",
       "      <td>70216.02</td>\n",
       "      <td>215304.70</td>\n",
       "      <td>57243.78</td>\n",
       "      <td>67538.61</td>\n",
       "      <td>301868.55</td>\n",
       "      <td>45289.71</td>\n",
       "      <td>200126.97</td>\n",
       "      <td>99121.12</td>\n",
       "      <td>79086.00</td>\n",
       "      <td>10197193.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7261088.04</td>\n",
       "      <td>118917.12</td>\n",
       "      <td>178083.00</td>\n",
       "      <td>99840.15</td>\n",
       "      <td>66552.40</td>\n",
       "      <td>115056.54</td>\n",
       "      <td>...</td>\n",
       "      <td>37900.00</td>\n",
       "      <td>79485.00</td>\n",
       "      <td>135654.40</td>\n",
       "      <td>56820.66</td>\n",
       "      <td>53071.20</td>\n",
       "      <td>75540.00</td>\n",
       "      <td>31273.56</td>\n",
       "      <td>50951.73</td>\n",
       "      <td>68079.56</td>\n",
       "      <td>6303831.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  date  product_id    09:30:00    09:35:00   09:40:00   09:45:00  \\\n",
       "5    6     1         267  8091607.23   200855.00  254585.18  182094.78   \n",
       "22  23     1         409  3967038.72    49270.40   72597.00   49056.54   \n",
       "28  29     1         447         NaN  4902746.25  123692.64  126432.00   \n",
       "29  30     1         449  5642713.00   168978.59  252366.66  212968.04   \n",
       "59  60     1         839         NaN  7261088.04  118917.12  178083.00   \n",
       "\n",
       "     09:50:00   09:55:00   10:00:00     ...        13:15:00   13:20:00  \\\n",
       "5   239248.65  295739.52  224983.14     ...       134951.50  172651.50   \n",
       "22  105244.80  109664.24   72702.00     ...        94930.00  109808.12   \n",
       "28   90729.22  225985.34  127063.09     ...        45155.70  116440.34   \n",
       "29   92013.80  102185.00  186739.00     ...        70216.02  215304.70   \n",
       "59   99840.15   66552.40  115056.54     ...        37900.00   79485.00   \n",
       "\n",
       "     13:25:00  13:30:00   13:35:00   13:40:00   13:45:00   13:50:00  \\\n",
       "5   231768.23       NaN   10164.00  161273.64  245219.00  118459.64   \n",
       "22   53813.32  32897.56  142312.95   20532.20   20807.80   38365.11   \n",
       "28  106385.16  89622.00  124051.29   68860.00   79177.41  299000.72   \n",
       "29   57243.78  67538.61  301868.55   45289.71  200126.97   99121.12   \n",
       "59  135654.40  56820.66   53071.20   75540.00   31273.56   50951.73   \n",
       "\n",
       "     13:55:00       TARGET  \n",
       "5    70953.90   7669334.76  \n",
       "22        NaN   3591258.75  \n",
       "28  185450.66   9088162.46  \n",
       "29   79086.00  10197193.80  \n",
       "59   68079.56   6303831.45  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = missing_training.iloc[30,]\n",
    "\n",
    "def fill_missing_l2(row):\n",
    "    \n",
    "    temp_filled = train_filled[train_filled['product_id'] == row['product_id']]\n",
    "    dist = []\n",
    "\n",
    "    for i, r_filled in temp_filled.iterrows():\n",
    "\n",
    "        dist.append(np.linalg.norm([r_filled[row.notnull()], row[row.notnull()]]))\n",
    "\n",
    "    arg = np.array(dist).argmin()\n",
    "\n",
    "    temp_remplace = temp_filled.iloc[arg]\n",
    "    row[!row.notnull()] = temp_remplace[!row.notnull()]\n",
    "    \n",
    "    return row\n",
    "\n",
    "print fill_missing_l2(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filled = test.drop(pd.isnull(test).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "test_missing = test[~test[\"ID\"].isin(test_filled[\"ID\"].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows only contain missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>618565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346856</th>\n",
       "      <td>1</td>\n",
       "      <td>967950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346872</th>\n",
       "      <td>1</td>\n",
       "      <td>967966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346876</th>\n",
       "      <td>1</td>\n",
       "      <td>967970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346880</th>\n",
       "      <td>1</td>\n",
       "      <td>967974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        COUNT      ID\n",
       "8           1  618565\n",
       "346856      1  967950\n",
       "346872      1  967966\n",
       "346876      1  967970\n",
       "346880      1  967974"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = test_filled.columns.drop([\"ID\", \"date\", \"product_id\"])\n",
    "test_count = pd.DataFrame(test_missing[numeric_cols].applymap(np.isnan).sum(axis=1))\n",
    "test_count.columns = [\"COUNT\"]\n",
    "test_count[\"ID\"] = test_missing.ix[test_count.index][\"ID\"]\n",
    "test_count.sort_values(by=\"COUNT\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer\n",
    "Create one imputer per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = {}\n",
    "\n",
    "numeric_cols = train.columns.drop([\"ID\", \"date\", \"product_id\", \"TARGET\"])\n",
    "for idx, product in enumerate(train[\"product_id\"].unique()):\n",
    "    print \"Product ID :\", product\n",
    "    print \"Progression :\", float(idx)/len(train[\"product_id\"].unique()) * 100, \"%\"\n",
    "    \n",
    "    # Fit an imputer for the selected 'product_id' on filled training data.\n",
    "    # Transform the associated data with missing values.\n",
    "    \n",
    "    train_filled_p = train_filled[train_filled[\"product_id\"] == product]\n",
    "    train_missing_p = train_missing[train_missing[\"product_id\"] == product]\n",
    "    \n",
    "    imp[product] = Imputer(strategy=\"median\", axis=0).fit(train_filled_p[numeric_cols])\n",
    "    train_missing[train_missing[\"product_id\"] == product][numeric_cols] = imp[product].\\\n",
    "        transform(train_missing_p[numeric_cols].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset for our supervised learning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b088fdea51e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_filled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"product_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TARGET\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_filled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TARGET\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "x = train_filled.drop([\"ID\", \"date\", \"product_id\", \"TARGET\"], axis=1).values\n",
    "y = train_filled[\"TARGET\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full labelled set :\n",
      "(513947, 54) \n",
      "(513947,)\n"
     ]
    }
   ],
   "source": [
    "print \"Full labelled set :\\n\", x.shape, \"\\n\", y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average target per product â€” this will be used when controlling the error of predictions for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>24157732.043920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>5825229.925770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>19649724.759512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>8249545.655585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261</td>\n",
       "      <td>30402004.119214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           TARGET\n",
       "0         236  24157732.043920\n",
       "1         238   5825229.925770\n",
       "2         242  19649724.759512\n",
       "3         243   8249545.655585\n",
       "4         261  30402004.119214"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_target_per_product = train.groupby(\"product_id\").mean()[\"TARGET\"].reset_index()\n",
    "average_target_per_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create wavelet dictionary.\n",
    "NB: 'db1' is the classical DFT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wave_name = 'db20'\n",
    "wave_level = None\n",
    "wavelet_operator_t = DictT(level=wave_level, name=wave_name)\n",
    "\n",
    "basis_t = wavelet_operator_t.dot(np.identity(x.shape[1]))\n",
    "basis_t /= np.sqrt(np.sum(basis_t ** 2, axis=0))\n",
    "basis = basis_t.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model.\n",
    "Training, validation split the transformed data, using Fourier/Wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x.dot(basis), y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :\n",
      "(359762, 54) \n",
      "(359762,)\n",
      "Validation set :\n",
      "(154185, 54) \n",
      "(154185,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training set :\\n\", x_train.shape, \"\\n\", y_train.shape\n",
    "print \"Validation set :\\n\", x_val.shape, \"\\n\", y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning method.    \n",
    "_TODO:_ Use GridSearchCV for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 Âµs, sys: 3 Âµs, total: 46 Âµs\n",
      "Wall time: 47 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "reg_grid = {\n",
    "    \"max_depth\": [10, 20, 40, None],\n",
    "    \"max_features\": [20, 30, 40, 'auto'],\n",
    "    \"min_samples_split\": [1, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "reg = GridSearchCV(RandomForestRegressor(n_estimators=50, n_jobs=-1),\n",
    "                   param_grid=reg_grid, n_jobs=-1, verbose=5)\n",
    "\"\"\"\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=15, \n",
    "                            max_features=20, \n",
    "                            min_samples_split=1, \n",
    "                            bootstrap=True, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "reg.fit(x_train, y_train)\n",
    "y_val_pred = reg.predict(x_val)\n",
    "\n",
    "# params = reg.best_params_\n",
    "# print params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "\n",
    "    \"\"\"\n",
    "    Note: does not handle mix 1d representation\n",
    "    if _is_1d(y_true): \n",
    "        y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print \"MAPE :\", mean_absolute_percentage_error(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training rows contain no missing entry, use the supervised learning method reg.    \n",
    "Otherwise, simply output the average target per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_filled = test.drop(pd.isnull(test).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "test_missing = test[~test[\"ID\"].isin(test_filled[\"ID\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.fit(x.dot(basis), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all test rows without any missing values, predict the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_filled_values(filled_dataframe, reg):\n",
    "    \n",
    "    y = reg.predict(filled_dataframe.drop([\"ID\", \"date\", \"product_id\"], axis=1).values.dot(basis))\n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_y.columns = [\"TARGET\"]\n",
    "    df_y[\"ID\"] = filled_dataframe[\"ID\"]\n",
    "    \n",
    "    return df_y[[\"ID\", \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test rows with missing values, just set the output to the average target per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_missing_values(missing_dataframe):\n",
    "    \n",
    "    df = pd.merge(missing_dataframe.reset_index(), average_target_per_product, on=\"product_id\")\n",
    "    df = df.sort_values(by=\"index\").reset_index()\n",
    "    return df[[\"ID\", \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate predictions to obtain the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_all_values(filled, missing, reg):\n",
    "    \n",
    "    return pd.concat([predict_filled_values(filled, reg), \n",
    "                      predict_missing_values(missing)], axis=0).sort_values(by=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618557</td>\n",
       "      <td>20148047.066664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618558</td>\n",
       "      <td>4388666.535405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618559</td>\n",
       "      <td>7456074.494341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>618560</td>\n",
       "      <td>5233019.985268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618561</td>\n",
       "      <td>15595865.176292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           TARGET\n",
       "0  618557  20148047.066664\n",
       "1  618558   4388666.535405\n",
       "2  618559   7456074.494341\n",
       "3  618560   5233019.985268\n",
       "4  618561  15595865.176292"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = predict_all_values(test_filled, test_missing, reg)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_test.to_csv(\"Submission.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
