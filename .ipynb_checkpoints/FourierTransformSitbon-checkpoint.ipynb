{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transform Class.\n",
    "DictT.dot is a method corresponding to the DWT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictT(object):\n",
    "\n",
    "    def __init__(self, name, level):\n",
    "            self.name = name\n",
    "            self.level = level\n",
    "            self.sizes = []\n",
    "\n",
    "    def dot(self, mat):\n",
    "\n",
    "        m = []\n",
    "\n",
    "        if mat.shape[0] != mat.size:\n",
    "            for i in xrange(mat.shape[1]):\n",
    "                c = pywt.wavedec(mat[:, i], self.name, level=self.level)\n",
    "                self.sizes.append(map(len, c))\n",
    "                c = np.concatenate(c)\n",
    "                m.append(c)\n",
    "            return np.asarray(m).T\n",
    "        else:\n",
    "            c = pywt.wavedec(mat, self.name, level=self.level)\n",
    "            self.sizes.append(map(len, c))\n",
    "            return np.concatenate(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('Data/training_input.csv', delimiter=',')\n",
    "output = pd.read_csv('Data/training_output.csv', delimiter=';')\n",
    "testing = pd.read_csv('Data/testing_input.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_filled = training.drop(pd.isnull(training).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "training_filled = pd.merge(training_filled, output, on='ID', how='inner')\n",
    "\n",
    "x = training_filled.drop([\"ID\", \"date\", \"product_id\", \"TARGET\"], axis=1).values\n",
    "y = training_filled[\"TARGET\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full labelled set :\n",
      "(513947L, 54L) \n",
      "(513947L,)\n"
     ]
    }
   ],
   "source": [
    "print \"Full labelled set :\\n\", x.shape, \"\\n\", y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create wavelet dictionary.\n",
    "NB: 'db1' is the classical DFT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wave_name = 'db20'\n",
    "wave_level = None\n",
    "wavelet_operator_t = DictT(level=wave_level, name=wave_name)\n",
    "\n",
    "basis_t = wavelet_operator_t.dot(np.identity(x.shape[1]))\n",
    "basis_t /= np.sqrt(np.sum(basis_t ** 2, axis=0))\n",
    "basis = basis_t.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model.\n",
    "Training, validation split the transformed data, using Fourier/Wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x.dot(basis), y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :\n",
      "(359762L, 54L) \n",
      "(359762L,)\n",
      "Validation set :\n",
      "(154185L, 54L) \n",
      "(154185L,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training set :\\n\", x_train.shape, \"\\n\", y_train.shape\n",
    "print \"Validation set :\\n\", x_val.shape, \"\\n\", y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning method.    \n",
    "_TODO:_ Use GridSearchCV for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   31.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 15\n",
      "building tree 2 of 15\n",
      "building tree 3 of 15\n",
      "building tree 4 of 15\n",
      "building tree 5 of 15\n",
      "building tree 6 of 15\n",
      "building tree 7 of 15\n",
      "building tree 8 of 15\n",
      "building tree 9 of 15\n",
      "building tree 10 of 15\n",
      "building tree 11 of 15\n",
      "building tree 12 of 15\n",
      "building tree 13 of 15\n",
      "building tree 14 of 15\n",
      "building tree 15 of 15\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "reg_grid = {\n",
    "    \"max_depth\": [10, 20, 40, None],\n",
    "    \"max_features\": [20, 30, 40, 'auto'],\n",
    "    \"min_samples_split\": [1, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "reg = GridSearchCV(RandomForestRegressor(n_estimators=50, n_jobs=-1),\n",
    "                   param_grid=reg_grid, n_jobs=-1, verbose=5)\n",
    "\"\"\"\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=15, \n",
    "                            max_features=20, \n",
    "                            min_samples_split=1, \n",
    "                            bootstrap=True, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "reg.fit(x_train, y_train)\n",
    "y_val_pred = reg.predict(x_val)\n",
    "\n",
    "# params = reg.best_params_\n",
    "# print params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE : 30.5255365345\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "\n",
    "    \"\"\"\n",
    "    Note: does not handle mix 1d representation\n",
    "    if _is_1d(y_true): \n",
    "        y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print \"MAPE on non missing:\", mean_absolute_percentage_error(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>24157732.043920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>5825229.925770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>19649724.759512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>8249545.655585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261</td>\n",
       "      <td>30402004.119214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           TARGET\n",
       "0         236  24157732.043920\n",
       "1         238   5825229.925770\n",
       "2         242  19649724.759512\n",
       "3         243   8249545.655585\n",
       "4         261  30402004.119214"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Les donnes manquantes a predire\n",
    "training_missing = training_temp[~training_temp[\"ID\"].isin(training_filled[\"ID\"].tolist())]\n",
    "print ('Shape training_missing')\n",
    "print training_missing.shape\n",
    "\n",
    "## MEAN OF EACH LABEL GROUPED BY PROD ID ##\n",
    "training_temp = pd.merge(training, output, on='ID', how='inner')\n",
    "Mean=training_temp.groupby(\"product_id\").mean()[\"TARGET\"].reset_index()\n",
    "print Mean.shape\n",
    "Mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape df_pred_missing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99273, 2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_target_per_product = training_temp.groupby(\"product_id\").mean()[\"TARGET\"].reset_index()\n",
    "average_target_per_product.head()\n",
    "df_pred_missing = pd.merge(training_missing[[\"product_id\",\"ID\"]], \n",
    "\n",
    "                           average_target_per_product, on='product_id', how='inner')\n",
    "df_pred_missing=df_pred_missing.drop([\"product_id\"],axis=1)\n",
    "print('Shape df_pred_missing')\n",
    "df_pred_missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253458, 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted = pd.DataFrame(y_val_pred)\n",
    "df_predicted.columns = [\"TARGET\"]\n",
    "df_predicted[\"ID\"] = training_filled[\"ID\"]\n",
    "cols = df_predicted.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_predicted = df_predicted[cols]\n",
    "df_predicted.head()\n",
    "df_predicted=df_predicted.append(df_pred_missing)\n",
    "df_predicted.sort_values(by=[\"ID\"],axis=0,inplace=True)\n",
    "df_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (253458L,)\n",
      "MAPE on non missing:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (613220,) (253458,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-51b175587cac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TARGET\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"MAPE on non missing:\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-490836bafead>\u001b[0m in \u001b[0;36mmean_absolute_percentage_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"MAPE :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (613220,) (253458,) "
     ]
    }
   ],
   "source": [
    "y_pred=df_predicted[\"TARGET\"].values\n",
    "print y_pred.shape\n",
    "y_val=output[\"TARGET\"].values\n",
    "print \"MAPE on non missing:\",  mean_absolute_percentage_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>09:30:00</th>\n",
       "      <th>09:35:00</th>\n",
       "      <th>09:40:00</th>\n",
       "      <th>09:45:00</th>\n",
       "      <th>09:50:00</th>\n",
       "      <th>09:55:00</th>\n",
       "      <th>10:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>13:10:00</th>\n",
       "      <th>13:15:00</th>\n",
       "      <th>13:20:00</th>\n",
       "      <th>13:25:00</th>\n",
       "      <th>13:30:00</th>\n",
       "      <th>13:35:00</th>\n",
       "      <th>13:40:00</th>\n",
       "      <th>13:45:00</th>\n",
       "      <th>13:50:00</th>\n",
       "      <th>13:55:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>618565</td>\n",
       "      <td>1885</td>\n",
       "      <td>305</td>\n",
       "      <td>217974.0102</td>\n",
       "      <td>85480.0040</td>\n",
       "      <td>83343.0039</td>\n",
       "      <td>59808.0028</td>\n",
       "      <td>64050.0000</td>\n",
       "      <td>34095.9984</td>\n",
       "      <td>115182.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>46750.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65906.0000</td>\n",
       "      <td>38268.0000</td>\n",
       "      <td>36142.0000</td>\n",
       "      <td>29764.0000</td>\n",
       "      <td>106450.0050</td>\n",
       "      <td>97888.0046</td>\n",
       "      <td>6384.0003</td>\n",
       "      <td>38304.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>618570</td>\n",
       "      <td>1885</td>\n",
       "      <td>389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4623800.0000</td>\n",
       "      <td>11895392.4016</td>\n",
       "      <td>4787485.8394</td>\n",
       "      <td>3363008.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>253700.0000</td>\n",
       "      <td>463934.9843</td>\n",
       "      <td>417501.0141</td>\n",
       "      <td>1034086.9651</td>\n",
       "      <td>1193136.0000</td>\n",
       "      <td>1289775.0000</td>\n",
       "      <td>573017.0193</td>\n",
       "      <td>905616.0304</td>\n",
       "      <td>1164240.0392</td>\n",
       "      <td>476000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>618583</td>\n",
       "      <td>1885</td>\n",
       "      <td>435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893935.9472</td>\n",
       "      <td>1350027.9624</td>\n",
       "      <td>502320.0140</td>\n",
       "      <td>1309547.9634</td>\n",
       "      <td>1758900.0000</td>\n",
       "      <td>1521672.0426</td>\n",
       "      <td>...</td>\n",
       "      <td>143899.9940</td>\n",
       "      <td>252104.9965</td>\n",
       "      <td>352996.0049</td>\n",
       "      <td>129492.0036</td>\n",
       "      <td>208742.0087</td>\n",
       "      <td>136819.0038</td>\n",
       "      <td>281150.9844</td>\n",
       "      <td>375232.0208</td>\n",
       "      <td>1229100.0510</td>\n",
       "      <td>600339.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>618585</td>\n",
       "      <td>1885</td>\n",
       "      <td>447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>303665.9893</td>\n",
       "      <td>136607.9952</td>\n",
       "      <td>227840.0000</td>\n",
       "      <td>73970.0026</td>\n",
       "      <td>136704.0000</td>\n",
       "      <td>51210.0018</td>\n",
       "      <td>...</td>\n",
       "      <td>25686.0009</td>\n",
       "      <td>423280.0000</td>\n",
       "      <td>180243.0063</td>\n",
       "      <td>88691.0031</td>\n",
       "      <td>31482.0011</td>\n",
       "      <td>232308.0000</td>\n",
       "      <td>129285.0000</td>\n",
       "      <td>134890.0047</td>\n",
       "      <td>89000.9969</td>\n",
       "      <td>140924.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>618616</td>\n",
       "      <td>1885</td>\n",
       "      <td>839</td>\n",
       "      <td>242339.9940</td>\n",
       "      <td>246256.9939</td>\n",
       "      <td>478608.0118</td>\n",
       "      <td>283290.0070</td>\n",
       "      <td>97176.0048</td>\n",
       "      <td>230393.9886</td>\n",
       "      <td>161440.0040</td>\n",
       "      <td>...</td>\n",
       "      <td>167916.0000</td>\n",
       "      <td>87956.0000</td>\n",
       "      <td>63952.0016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31976.0008</td>\n",
       "      <td>15983.9996</td>\n",
       "      <td>151924.0000</td>\n",
       "      <td>63984.0032</td>\n",
       "      <td>99950.0000</td>\n",
       "      <td>75962.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  date  product_id     09:30:00      09:35:00      09:40:00  \\\n",
       "8   618565  1885         305  217974.0102    85480.0040    83343.0039   \n",
       "13  618570  1885         389          NaN           NaN           NaN   \n",
       "26  618583  1885         435          NaN  1893935.9472  1350027.9624   \n",
       "28  618585  1885         447          NaN   303665.9893   136607.9952   \n",
       "59  618616  1885         839  242339.9940   246256.9939   478608.0118   \n",
       "\n",
       "        09:45:00       09:50:00      09:55:00      10:00:00     ...       \\\n",
       "8     59808.0028     64050.0000    34095.9984   115182.0000     ...        \n",
       "13  4623800.0000  11895392.4016  4787485.8394  3363008.0000     ...        \n",
       "26   502320.0140   1309547.9634  1758900.0000  1521672.0426     ...        \n",
       "28   227840.0000     73970.0026   136704.0000    51210.0018     ...        \n",
       "59   283290.0070     97176.0048   230393.9886   161440.0040     ...        \n",
       "\n",
       "       13:10:00     13:15:00     13:20:00      13:25:00      13:30:00  \\\n",
       "8    46750.0000          NaN   65906.0000    38268.0000    36142.0000   \n",
       "13  253700.0000  463934.9843  417501.0141  1034086.9651  1193136.0000   \n",
       "26  143899.9940  252104.9965  352996.0049   129492.0036   208742.0087   \n",
       "28   25686.0009  423280.0000  180243.0063    88691.0031    31482.0011   \n",
       "59  167916.0000   87956.0000   63952.0016           NaN    31976.0008   \n",
       "\n",
       "        13:35:00     13:40:00     13:45:00      13:50:00     13:55:00  \n",
       "8     29764.0000  106450.0050   97888.0046     6384.0003   38304.0018  \n",
       "13  1289775.0000  573017.0193  905616.0304  1164240.0392  476000.0000  \n",
       "26   136819.0038  281150.9844  375232.0208  1229100.0510  600339.0166  \n",
       "28   232308.0000  129285.0000  134890.0047    89000.9969  140924.0000  \n",
       "59    15983.9996  151924.0000   63984.0032    99950.0000   75962.0000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_filled = testing.drop(pd.isnull(testing).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "testing_missing = testing[~testing[\"ID\"].isin(testing_filled[\"ID\"].tolist())]\n",
    "testing_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all test rows without any missing values, predict the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   48.4s finished\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 15\n",
      "building tree 2 of 15\n",
      "building tree 3 of 15\n",
      "building tree 4 of 15\n",
      "building tree 5 of 15\n",
      "building tree 6 of 15\n",
      "building tree 7 of 15\n",
      "building tree 8 of 15\n",
      "building tree 9 of 15\n",
      "building tree 10 of 15\n",
      "building tree 11 of 15\n",
      "building tree 12 of 15\n",
      "building tree 13 of 15\n",
      "building tree 14 of 15\n",
      "building tree 15 of 15\n"
     ]
    }
   ],
   "source": [
    "x_test = testing_filled.drop([\"ID\", \"date\", \"product_id\"], axis=1).values\n",
    "reg.fit(x.dot(basis), y)\n",
    "y_test = reg.predict(x_test.dot(basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618557</td>\n",
       "      <td>17557246.736756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618558</td>\n",
       "      <td>5377269.929739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618559</td>\n",
       "      <td>7799878.915360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>618560</td>\n",
       "      <td>5163657.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618561</td>\n",
       "      <td>18556182.437674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           TARGET\n",
       "0  618557  17557246.736756\n",
       "1  618558   5377269.929739\n",
       "2  618559   7799878.915360\n",
       "3  618560   5163657.082650\n",
       "4  618561  18556182.437674"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(y_test)\n",
    "df_test.columns = [\"TARGET\"]\n",
    "df_test[\"ID\"] = testing_filled[\"ID\"]\n",
    "cols = df_test.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_test = df_test[cols]\n",
    "df_test.head()\n",
    "# df_test.to_csv(\"Submission.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test rows with missing values, just set the output to the average target per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618565</td>\n",
       "      <td>5328192.005324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618917</td>\n",
       "      <td>5328192.005324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621528</td>\n",
       "      <td>5328192.005324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622481</td>\n",
       "      <td>5328192.005324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623724</td>\n",
       "      <td>5328192.005324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID          TARGET\n",
       "0  618565  5328192.005324\n",
       "1  618917  5328192.005324\n",
       "2  621528  5328192.005324\n",
       "3  622481  5328192.005324\n",
       "4  623724  5328192.005324"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_missing = pd.merge(testing_missing[[\"product_id\",\"ID\"]], \n",
    "\n",
    "                           average_target_per_product, on='product_id', how='inner')\n",
    "df_test_missing=df_test_missing.drop([\"product_id\"],axis=1)\n",
    "df_test_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618558</td>\n",
       "      <td>5377269.929739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618559</td>\n",
       "      <td>7799878.915360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>618560</td>\n",
       "      <td>5163657.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618561</td>\n",
       "      <td>18556182.437674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>618562</td>\n",
       "      <td>6326199.772999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>618563</td>\n",
       "      <td>35825234.065468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>618564</td>\n",
       "      <td>52795442.439919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618565</td>\n",
       "      <td>4450988.227835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>618566</td>\n",
       "      <td>22945040.609989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           TARGET\n",
       "1  618558   5377269.929739\n",
       "2  618559   7799878.915360\n",
       "3  618560   5163657.082650\n",
       "4  618561  18556182.437674\n",
       "5  618562   6326199.772999\n",
       "6  618563  35825234.065468\n",
       "7  618564  52795442.439919\n",
       "0  618565   4450988.227835\n",
       "8  618566  22945040.609989"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission=df_test.append(df_test_missing)\n",
    "df_submission.sort_values(by=[\"ID\"],axis=0,inplace=True)\n",
    "df_submission[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
