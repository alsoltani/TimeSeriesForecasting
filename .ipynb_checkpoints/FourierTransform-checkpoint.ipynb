{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transform Class.\n",
    "DictT.dot is a method corresponding to the DWT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictT(object):\n",
    "\n",
    "    def __init__(self, name, level):\n",
    "            self.name = name\n",
    "            self.level = level\n",
    "            self.sizes = []\n",
    "\n",
    "    def dot(self, mat):\n",
    "\n",
    "        m = []\n",
    "\n",
    "        if mat.shape[0] != mat.size:\n",
    "            for i in xrange(mat.shape[1]):\n",
    "                c = pywt.wavedec(mat[:, i], self.name, level=self.level)\n",
    "                self.sizes.append(map(len, c))\n",
    "                c = np.concatenate(c)\n",
    "                m.append(c)\n",
    "            return np.asarray(m).T\n",
    "        else:\n",
    "            c = pywt.wavedec(mat, self.name, level=self.level)\n",
    "            self.sizes.append(map(len, c))\n",
    "            return np.concatenate(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('Data/training_input.csv', delimiter=',')\n",
    "output = pd.read_csv('Data/training_output.csv', delimiter=';')\n",
    "testing = pd.read_csv('Data/testing_input.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Interpolate the training input ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = testing.interpolate(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = training.drop(pd.isnull(training).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "training = pd.merge(training, output, on='ID', how='inner')\n",
    "\n",
    "x = training.drop([\"ID\", \"date\", \"product_id\", \"TARGET\"], axis=1).values\n",
    "y = training[\"TARGET\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full labelled set :\n",
      "(513947, 54) \n",
      "(513947,)\n"
     ]
    }
   ],
   "source": [
    "print \"Full labelled set :\\n\", x.shape, \"\\n\", y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create wavelet dictionary.\n",
    "NB: 'db1' is the classical DFT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wave_name = 'db17'\n",
    "wave_level = None\n",
    "wavelet_operator_t = DictT(level=wave_level, name=wave_name)\n",
    "\n",
    "basis_t = wavelet_operator_t.dot(np.identity(x.shape[1]))\n",
    "basis_t /= np.sqrt(np.sum(basis_t ** 2, axis=0))\n",
    "basis = basis_t.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model.\n",
    "Training, validation split the transformed data, using Fourier/Wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x.dot(basis), y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :\n",
      "(411157, 54) \n",
      "(411157,)\n",
      "Validation set :\n",
      "(102790, 54) \n",
      "(102790,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training set :\\n\", x_train.shape, \"\\n\", y_train.shape\n",
    "print \"Validation set :\\n\", x_val.shape, \"\\n\", y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning method.    \n",
    "_TODO:_ Use GridSearchCV for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 15\n",
      "building tree 2 of 15\n",
      "building tree 3 of 15\n",
      "building tree 4 of 15\n",
      "building tree 5 of 15\n",
      "building tree 6 of 15\n",
      "building tree 7 of 15\n",
      "building tree 8 of 15\n",
      "building tree 9 of 15\n",
      "building tree 10 of 15\n",
      "building tree 11 of 15\n",
      "building tree 12 of 15\n",
      "building tree 13 of 15\n",
      "building tree 14 of 15\n",
      "building tree 15 of 15\n",
      "CPU times: user 4min 9s, sys: 1.21 s, total: 4min 10s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "reg_grid = {\n",
    "    \"max_depth\": [10, 20, 40, None],\n",
    "    \"max_features\": [20, 30, 40, 'auto'],\n",
    "    \"min_samples_split\": [1, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "reg = GridSearchCV(RandomForestRegressor(n_estimators=50, n_jobs=-1),\n",
    "                   param_grid=reg_grid, n_jobs=-1, verbose=5)\n",
    "\"\"\"\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=15, \n",
    "                            max_features=20, \n",
    "                            min_samples_split=1, \n",
    "                            bootstrap=True, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "reg.fit(x_train, y_train)\n",
    "y_val_pred = reg.predict(x_val)\n",
    "\n",
    "# params = reg.best_params_\n",
    "# print params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE : 30.9492386531\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "\n",
    "    \"\"\"\n",
    "    Note: does not handle mix 1d representation\n",
    "    if _is_1d(y_true): \n",
    "        y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print \"MAPE :\", mean_absolute_percentage_error(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = testing.drop([\"ID\", \"date\", \"product_id\"], axis=1).values\n",
    "reg.fit(x.dot(basis), y)\n",
    "y_test = reg.predict(x_test.dot(basis))\n",
    "\n",
    "df_test = pd.DataFrame(y_test).reset_index()\n",
    "df.columns = [\"ID\", \"TARGET\"]\n",
    "df[\"ID\"] = df[\"ID\"].apply(lambda r: r+1)\n",
    "df.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
