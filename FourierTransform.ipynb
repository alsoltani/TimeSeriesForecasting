{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Transform Class.\n",
    "DictT.dot is a method corresponding to the DWT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DictT(object):\n",
    "\n",
    "    def __init__(self, name, level):\n",
    "            self.name = name\n",
    "            self.level = level\n",
    "            self.sizes = []\n",
    "\n",
    "    def dot(self, mat):\n",
    "\n",
    "        m = []\n",
    "\n",
    "        if mat.shape[0] != mat.size:\n",
    "            for i in xrange(mat.shape[1]):\n",
    "                c = pywt.wavedec(mat[:, i], self.name, level=self.level)\n",
    "                self.sizes.append(map(len, c))\n",
    "                c = np.concatenate(c)\n",
    "                m.append(c)\n",
    "            return np.asarray(m).T\n",
    "        else:\n",
    "            c = pywt.wavedec(mat, self.name, level=self.level)\n",
    "            self.sizes.append(map(len, c))\n",
    "            return np.concatenate(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/training_input.csv', delimiter=',')\n",
    "output = pd.read_csv('Data/training_output.csv', delimiter=';')\n",
    "test = pd.read_csv('Data/testing_input.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows with no or several missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, output, on='ID', how='inner')\n",
    "train_filled = train.drop(pd.isnull(train).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "train_missing = train[~train[\"ID\"].isin(train_filled[\"ID\"].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset for our supervised learning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = train_filled.drop([\"ID\", \"date\", \"product_id\", \"TARGET\"], axis=1).values\n",
    "y = train_filled[\"TARGET\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full labelled set :\n",
      "(513947, 54) \n",
      "(513947,)\n"
     ]
    }
   ],
   "source": [
    "print \"Full labelled set :\\n\", x.shape, \"\\n\", y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average target per product — this will be used when controlling the error of predictions for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>24157732.043920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>5825229.925770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242</td>\n",
       "      <td>19649724.759512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>8249545.655585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261</td>\n",
       "      <td>30402004.119214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id           TARGET\n",
       "0         236  24157732.043920\n",
       "1         238   5825229.925770\n",
       "2         242  19649724.759512\n",
       "3         243   8249545.655585\n",
       "4         261  30402004.119214"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_target_per_product = train.groupby(\"product_id\").mean()[\"TARGET\"].reset_index()\n",
    "average_target_per_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create wavelet dictionary.\n",
    "NB: 'db1' is the classical DFT operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wave_name = 'db20'\n",
    "wave_level = None\n",
    "wavelet_operator_t = DictT(level=wave_level, name=wave_name)\n",
    "\n",
    "basis_t = wavelet_operator_t.dot(np.identity(x.shape[1]))\n",
    "basis_t /= np.sqrt(np.sum(basis_t ** 2, axis=0))\n",
    "basis = basis_t.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model.\n",
    "Training, validation split the transformed data, using Fourier/Wavelet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x.dot(basis), y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :\n",
      "(359762, 54) \n",
      "(359762,)\n",
      "Validation set :\n",
      "(154185, 54) \n",
      "(154185,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training set :\\n\", x_train.shape, \"\\n\", y_train.shape\n",
    "print \"Validation set :\\n\", x_val.shape, \"\\n\", y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning method.    \n",
    "_TODO:_ Use GridSearchCV for the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 µs, sys: 3 µs, total: 46 µs\n",
      "Wall time: 47 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "reg_grid = {\n",
    "    \"max_depth\": [10, 20, 40, None],\n",
    "    \"max_features\": [20, 30, 40, 'auto'],\n",
    "    \"min_samples_split\": [1, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 5, 10],\n",
    "    \"bootstrap\": [True, False]}\n",
    "\n",
    "reg = GridSearchCV(RandomForestRegressor(n_estimators=50, n_jobs=-1),\n",
    "                   param_grid=reg_grid, n_jobs=-1, verbose=5)\n",
    "\"\"\"\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=15, \n",
    "                            max_features=20, \n",
    "                            min_samples_split=1, \n",
    "                            bootstrap=True, \n",
    "                            max_depth=20, \n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "reg.fit(x_train, y_train)\n",
    "y_val_pred = reg.predict(x_val)\n",
    "\n",
    "# params = reg.best_params_\n",
    "# print params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "\n",
    "    \"\"\"\n",
    "    Note: does not handle mix 1d representation\n",
    "    if _is_1d(y_true): \n",
    "        y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print \"MAPE :\", mean_absolute_percentage_error(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If training rows contain no missing entry, use the supervised learning method reg.    \n",
    "Otherwise, simply output the average target per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_filled = test.drop(pd.isnull(test).any(1).nonzero()[0]).reset_index(drop=True)\n",
    "test_missing = test[~test[\"ID\"].isin(test_filled[\"ID\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.fit(x.dot(basis), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all test rows without any missing values, predict the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_filled_values(filled_dataframe, reg):\n",
    "    \n",
    "    y = reg.predict(filled_dataframe.drop([\"ID\", \"date\", \"product_id\"], axis=1).values.dot(basis))\n",
    "    df_y = pd.DataFrame(y)\n",
    "    df_y.columns = [\"TARGET\"]\n",
    "    df_y[\"ID\"] = filled_dataframe[\"ID\"]\n",
    "    \n",
    "    return df_y[[\"ID\", \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test rows with missing values, just set the output to the average target per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_missing_values(missing_dataframe):\n",
    "    \n",
    "    df = pd.merge(missing_dataframe.reset_index(), average_target_per_product, on=\"product_id\")\n",
    "    df = df.sort_values(by=\"index\").reset_index()\n",
    "    return df[[\"ID\", \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate predictions to obtain the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_all_values(filled, missing, reg):\n",
    "    \n",
    "    return pd.concat([predict_filled_values(filled, reg), \n",
    "                      predict_missing_values(missing)], axis=0).sort_values(by=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>618557</td>\n",
       "      <td>20148047.066664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618558</td>\n",
       "      <td>4388666.535405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>618559</td>\n",
       "      <td>7456074.494341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>618560</td>\n",
       "      <td>5233019.985268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618561</td>\n",
       "      <td>15595865.176292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           TARGET\n",
       "0  618557  20148047.066664\n",
       "1  618558   4388666.535405\n",
       "2  618559   7456074.494341\n",
       "3  618560   5233019.985268\n",
       "4  618561  15595865.176292"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = predict_all_values(test_filled, test_missing, reg)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_test.to_csv(\"Submission.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
